---
layout: post
title: "AI is not a salve for your complex domain"
excerpt: 
date: 2025-11-25 15:51:15 -0600
categories: 
---

- The fundamental problem with AI as it relates to software product development and technology businesses
	- people (wave jazz hands) have never understood software
		- they don't even understand systems more broadly
			- they don't understand (or appreciate) the complexity
		- they have always thought of systems and software development process in the most simple-minded way possible
			- the age-old "cost center" problem
				- thinking AI will replace expensive software practitioners is no different than thinking offshoring all your development will
		- AI as a solution to a software development "problem" is just the latest in a long line of tech that business people think will eliminate:
			- complexity (this complexity is inherent)
			- time
			- labor
		- most of new AI features are actually just "regular" software
			- e.g.
				- "projects"
				- context management
				- agentic orchestration
			- new versions of foundational models are not improving outcomes for most users
				- [Claude Opus 4.5, and why evaluating new LLMs is increasingly difficult](https://simonwillison.net/2025/Nov/24/claude-opus/)
	- If Agile as Trauma -- Agile is a trauma response -- then what will the trauma response to this AI noise be?
		- if Agile was the response to the metaphorical equivalent of emotional abuse
		- and SAFe was the response to the metaphorical equivalent of physical abuse
		- what does this current wave of believing AI "coders" will solve your complexity problem represent? what will the trauma response be?

---

There's a pattern I keep seeing: business leaders who have never understood software development think they've finally found the solution that will make it all make sense. AI will be the thing that eliminates the complexity, reduces the time, cuts the labor costs. It's a familiar song, just with a new verse.

## The Fundamental Misunderstanding

The problem isn't new. People—and I'm waving my hands here in the general direction of business leadership, venture capitalists, and the entire cottage industry of productivity consultants—have never understood software. More broadly, they don't understand systems. They don't appreciate or even acknowledge the inherent complexity.

They've always thought about systems and software development in the most simple-minded way possible. Software is a cost center. Developers are expensive. Therefore, the solution is to find a way to need fewer developers, or cheaper developers, or no developers at all.

This is why offshoring became such a popular strategy in the 2000s. This is why low-code/no-code platforms have been hyped for decades. This is why every new technology wave brings predictions that "real programmers" will soon be obsolete. And now, it's why AI is being positioned as the ultimate replacement for expensive software practitioners.

The fundamental error is treating software development as a mechanical process rather than a knowledge work practice embedded in complex organizational and technical systems.

## What AI Actually Is (In This Context)

Here's something that often gets lost in the hype: most of the new "AI features" being sold to organizations are actually just regular software with a language model somewhere in the pipeline.

Consider what's being marketed as revolutionary AI capabilities:

- **"Projects"** - This is just project management software with an LLM interface
- **Context management** - This is retrieval and indexing with natural language queries
- **Agentic orchestration** - This is workflow automation with probabilistic decision points

These aren't bad things. Some of them are genuinely useful. But they're not magical, and they don't eliminate the underlying complexity of software development or organizational dynamics.

More tellingly, as Simon Willison notes in his post about Claude Opus 4.5, new versions of foundational models are not meaningfully improving outcomes for most users. The technology is hitting a plateau at the same time that the marketing hype is reaching fever pitch. This should tell us something about what's really being sold here.

## The Cost Center Fallacy

The "software as cost center" mentality reveals a deeper misunderstanding about how value is created in technology businesses. When you view developers primarily as an expense to be minimized, you optimize for all the wrong things.

You end up with:

- Gantt charts and rigid frameworks that prioritize control over outcomes
- Metrics and surveillance that degrade trust and psychological safety
- Processes designed to extract predictability from inherently uncertain work
- Organizations that drive away their best people while wondering why they can't hire fast enough

The irony is that in a market where software engineering talent is scarce enough that companies are recruiting globally and people are changing jobs every six months for dramatic salary increases, the response is often to double down on control mechanisms rather than addressing the root causes of dysfunction.

If you believe developers are interchangeable resources whose output can be measured and optimized through better tooling, then AI looks like the perfect solution. But if you understand that software development is knowledge work that depends on trust, collaboration, and deep domain understanding, then you realize AI is at best a tool that might help people do their work—not a replacement for the work itself.

## The Trauma Cycle

Dorian Taylor's concept of "Agile as Trauma" is illuminating here. Agile emerged as an immune response to bad management—specifically, to the waterfall methodology that treated software development like construction or manufacturing. The Agile Manifesto was, fundamentally, an expression of trauma from programmers who had been subjected to management practices that were actively hostile to how software actually gets built.

But because Agile was born as a reaction—a trauma response—it remained vulnerable to the very managerial impulses it sought to escape. And so we got SAFe and other frameworks that took the language of agility and used it to reimpose exactly the kind of top-down control that Agile was meant to resist.

If we follow this pattern:

- **Waterfall** represented the metaphorical equivalent of treating knowledge workers like factory workers—emotional invalidation at scale
- **Agile** was the trauma response—an attempt to create safety and autonomy
- **SAFe** was the re-traumatization—management co-opting the language of the trauma response to reassert control

So what does this current wave of believing AI "coders" will solve your complexity problem represent?

It feels like something worse. It's not just about control or predictability anymore. It's about elimination. The fantasy is not to manage developers better, or to structure their work more effectively, but to not need them at all.

And what will the trauma response be?

I suspect we're watching it emerge in real-time. Developers are leaving companies at unprecedented rates. The talent shortage is intensifying precisely because the places that would pay the most are often the places with the most dysfunctional cultures. The organizations that are most aggressively pursuing AI-as-replacement are the ones that will find themselves unable to retain or attract the expertise they need to actually build anything.

## What's Actually Needed

The hard truth is that there are no shortcuts to understanding complexity. You can't automate your way out of the need to deeply understand your domain. You can't use AI to paper over organizational dysfunction, trust deficits, or misaligned incentives.

The organizations that will actually benefit from AI are the ones that already have:

- Deep domain expertise
- Healthy team dynamics and high trust
- Clear alignment between stated values and actual incentives
- Leaders who understand that the purpose of a system is what it does, not what it claims to do

For everyone else, AI is just the latest in a long line of technological solutions to human problems—a salve that promises to eliminate the need to do the difficult work of building functional organizations.

But the complexity is inherent. The time cannot be compressed without trade-offs. The labor is valuable precisely because it represents accumulated knowledge and expertise.

AI might augment that expertise. It won't replace the need for it.

And until business leaders understand this, they'll keep reaching for the next silver bullet, wondering why their software initiatives keep failing, why their best people keep leaving, and why the absence of surprises they've optimized for keeps coinciding with the absence of substantive outcomes.
