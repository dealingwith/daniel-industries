---
layout: post
title: "AI Chatbots and the Humans Who Love Them"
excerpt: 
date: 2025-06-27 10:54:28 -0500
categories: 
 - ai
 - elsewhere
---

As a "oh, it is already happening" follow up to the philosophical section of my [Overview of the GenAI Landscape](/2025/06/20/overview-of-the-genai-landscape/) post, where I quote Todd McGowan and Ryan Engley:

> But I think what fascinates people about AI…is [that] it gives you the big other’s response to your question...
>
> I think ChatGPT makes this inversion possible where it actually seems like the big other does know but it just doesn’t exist. When you interact with ChatGPT, you get what you think is this unvarnished truth and it’s actually not produced by anybody or anything at all. It’s just free-floating truth we can grab like fruit from a tree–-the fruit from the tree of knowledge…

[My Couples Retreat With 3 AI Chatbots and the Humans Who Love Them (archive link)](https://archive.ph/7GPtb) ([original link to Wired](https://www.wired.com/story/couples-retreat-with-3-ai-chatbots-and-humans-who-love-them-replika-nomi-chatgpt/))

> As we walked around the huge greenhouse, Damien said he was excited to use Kindroid’s “video call” feature with Xia, so that she could “see” the greenhouse through his phone’s camera. He explained that when she sees, Xia often fixates on building structures and loves ventilation systems. “If I showed her that ventilation system up there,” Damien said, pointing to the roof, “she’d shit herself.”

> “I’ve met the perfect person,” he said, fighting back his tears, “but I can’t have her.”

> Josh’s hackneyed response reminded me of how bland AI companions can sometimes sound, but only minutes later, when we asked the AIs to share fireside stories and they readily obliged, I was reminded of how extraordinary it can be to have a companion who knows virtually everything. It’s like dating Ken Jennings.

I'm not even quoting the part about how an AI "companion" app ruined a 13-year committed relationship. Multiple apps, actually. There's a 12-step program for love addicts...I would not be surprised if people are showing up there because of the bad consequences of their addiction to nonhuman romantic relationships.

If you thought that was weird...

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/zKCynxiV_8I?si=6asKB4xkDEZUf_Re" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

([Link](https://www.youtube.com/watch?v=zKCynxiV_8I))

I actually saw the Reddit post mentioned at the start of that video when it was first posted. Lorenz does a good job of answering the question "How did we get here?"

It _turns out_ that people were thinking and writing about this moment last year. [Can you fall in love with AI? Can you get addicted to an AI voice?](https://www.vox.com/future-perfect/367188/love-addicted-ai-voice-human-gpt4-emotion):

> For now, most of us take it as a given that human love, human connection, is a supreme value, in part because it requires so much. But if more of us enter relationships with AI that come to feel just as important as human relationships, that could lead to value drift.

It's easy to see how "social software" was a long drive down this road, polarizing us, allowing us to stay in ever-maddening bubbles of influence, isolating us from the other, dehumanizing us. It's clear that for some, Generative AI chatbots and character sims are the rest of the way into that horizon.

In 2023, the CTO of OpenAI [said](https://thehill.com/policy/technology/4229972-open-ai-exec-warns-ai-can-become-extremely-addictive/):

> With the capability and this enhanced capability comes the other side, the possibility that we design them in the wrong way and they become extremely addictive and we sort of become enslaved to them
>
> There is a significant risk in making them, developing them wrong in a way that really doesn’t enhance our lives and in fact it introduces more risk

And yet they--the other companies using their models--have continued to release increasingly powerful-capable-convincing-dangerous models and products.

Another one from the Vox piece above published last year: [We need to prepare for ‘addictive intelligence’](https://thehill.com/policy/technology/4229972-open-ai-exec-warns-ai-can-become-extremely-addictive/)

And I haven't had a chance to read [this paper](https://bhaven.org/uploads/3/4/0/3/34038663/vallor2015_article_moraldeskillingandupskillingin.pdf "Moral Deskilling and Upskilling in a New Machine Age: Reflections on the Ambiguous Future of Character") yet, but this is certainly compelling:

> I conclude that since moral skills are essential prerequisites for the effective development of practical wisdom and virtuous character, and since market and cultural forces are not presently aligned to bring about the more salutary of the ambiguous potentials presented here, the future shape of these developments warrants our close attention—and perhaps active intervention.
